{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# STEP 1: SETUP AND IMPORTS\n# =============================================================================\n# This cell installs necessary libraries, downloads the dataset, and imports modules.\n\n!pip install torch torchtext==0.17.0 tqdm sacrebleu -q\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport unicodedata\nimport re\nimport random\nfrom collections import Counter\nfrom tqdm import tqdm\nimport math\nimport time\nimport sacrebleu\n\n# Download and extract the English-Indonesian dataset\n!wget -q http://www.manythings.org/anki/ind-eng.zip\n!unzip -n -q ind-eng.zip\n\nprint(\"âœ… Setup Complete. Dataset is ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:01:02.264920Z","iopub.execute_input":"2025-08-23T11:01:02.265607Z","iopub.status.idle":"2025-08-23T11:01:07.246332Z","shell.execute_reply.started":"2025-08-23T11:01:02.265581Z","shell.execute_reply":"2025-08-23T11:01:07.245506Z"}},"outputs":[{"name":"stdout","text":"âœ… Setup Complete. Dataset is ready.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# =============================================================================\n# STEP 2: DATA PREPARATION\n# =============================================================================\n# This section contains all functions for loading, cleaning, and preparing the data.\n\n# --- Define special tokens and their indices ---\nSPECIALS = [\"<pad>\", \"<bos>\", \"<eos>\"]\nPAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2\nUNK_IDX = None  # kita nggak pakai unk\n\ndef normalize_and_tokenize(s: str):\n    \"\"\"Cleans and tokenizes a string but keeps names and numbers.\"\"\"\n    s = s.strip()\n    # Add space before punctuation\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    # Replace multiple spaces with single space\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s.split()\n\ndef load_pairs(path, max_pairs=10000):\n    \"\"\"Loads, tokenizes, and filters sentence pairs from a file.\"\"\"\n    pairs = []\n    with open(path, encoding=\"utf-8\") as f:\n        for line in f:\n            cols = line.rstrip(\"\\n\").split(\"\\t\")\n            if len(cols) < 2:\n                continue\n            src, tgt = cols[0], cols[1]  # English, Indonesian\n            src_tokens = normalize_and_tokenize(src)\n            tgt_tokens = normalize_and_tokenize(tgt)\n\n            # --- Filter: buang kalimat aneh ---\n            if not src_tokens or not tgt_tokens:\n                continue\n            if len(src_tokens) > 100 or len(tgt_tokens) > 100:\n                continue\n            if abs(len(src_tokens) - len(tgt_tokens)) > 50:\n                continue\n\n            pairs.append((src_tokens, tgt_tokens))\n\n    random.shuffle(pairs)\n    return pairs[:max_pairs]\n\ndef build_vocab(token_lists, min_freq=1):\n    \"\"\"Builds a vocabulary from a list of tokenized sentences.\"\"\"\n    counter = Counter(tok for tokens in token_lists for tok in tokens)\n    vocab = {sp: i for i, sp in enumerate(SPECIALS)}\n    for word, freq in counter.items():\n        if freq >= min_freq:\n            vocab[word] = len(vocab)\n    itos = {i: w for w, i in vocab.items()}\n    return vocab, itos\n\ndef to_ids(tokens, vocab):\n    ids = []\n    for t in tokens:\n        if t in vocab:\n            ids.append(vocab[t])\n        else:\n            # fallback: kasih <pad> (atau bisa tambahin ke vocab dinamis)\n            ids.append(PAD_IDX)\n    return [BOS_IDX] + ids + [EOS_IDX]\n\nclass NMTDataset(Dataset):\n    \"\"\"Custom PyTorch Dataset for NMT.\"\"\"\n    def __init__(self, pairs, src_vocab, trg_vocab):\n        self.data = []\n        for src, trg in pairs:\n            src_ids = torch.tensor(to_ids(src, src_vocab), dtype=torch.long)\n            trg_ids = torch.tensor(to_ids(trg, trg_vocab), dtype=torch.long)\n            self.data.append((src_ids, trg_ids))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\ndef collate_batch(batch):\n    \"\"\"Pads sequences in a batch to the same length.\"\"\"\n    src_list, trg_list = [], []\n    for _src, _trg in batch:\n        src_list.append(_src)\n        trg_list.append(_trg)\n    src_pad = nn.utils.rnn.pad_sequence(src_list, padding_value=PAD_IDX)\n    trg_pad = nn.utils.rnn.pad_sequence(trg_list, padding_value=PAD_IDX)\n    return src_pad, trg_pad\n\n# --- Execute Data Preparation ---\npairs = load_pairs(\"ind.txt\", max_pairs=15000)\n\n# Split data: 80% train, 10% validation, 10% test\nn_train = int(len(pairs) * 0.8)\nn_val = int(len(pairs) * 0.1)\ntrain_pairs, val_pairs, test_pairs = pairs[:n_train], pairs[n_train:n_train+n_val], pairs[n_train+n_val:]\n\n# Build vocabularies from training data\nen_vocab, en_itos = build_vocab([p[0] for p in train_pairs])\nid_vocab, id_itos = build_vocab([p[1] for p in train_pairs])\n\n# Create DataLoaders\nBATCH_SIZE = 64\ntrain_loader = DataLoader(NMTDataset(train_pairs, en_vocab, id_vocab), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\nval_loader = DataLoader(NMTDataset(val_pairs, en_vocab, id_vocab), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\ntest_loader = DataLoader(NMTDataset(test_pairs, en_vocab, id_vocab), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n\nprint(f\"âœ… Data prepared: {len(train_pairs)} train, {len(val_pairs)} val, {len(test_pairs)} test pairs.\")\nprint(f\"   English vocab: {len(en_vocab)} | Indonesian vocab: {len(id_vocab)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:01:07.248007Z","iopub.execute_input":"2025-08-23T11:01:07.248242Z","iopub.status.idle":"2025-08-23T11:01:08.077039Z","shell.execute_reply.started":"2025-08-23T11:01:07.248220Z","shell.execute_reply":"2025-08-23T11:01:08.076296Z"}},"outputs":[{"name":"stdout","text":"âœ… Data prepared: 11904 train, 1488 val, 1489 test pairs.\n   English vocab: 5627 | Indonesian vocab: 6904\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# =============================================================================\n# STEP 3: MODEL DEFINITIONS\n# =============================================================================\n# This section contains the PyTorch classes for both the RNN and Transformer models.\n\n\n# -----------------------------------------------------\n# 3.0 Helper untuk Transformer\n# -----------------------------------------------------\ndef generate_square_subsequent_mask(sz: int):\n    \"\"\"Generate a square mask for the sequence. Masked positions are filled with -inf.\"\"\"\n    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\n# -----------------------------------------------------\n# 3.1 Baseline: RNN with Bahdanau Attention\n# -----------------------------------------------------\nclass BahdanauEncoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=PAD_IDX)\n        self.gru = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, hidden = self.gru(embedded)\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n        return outputs, hidden\n\n\nclass BahdanauAttention(nn.Module):\n    def __init__(self, enc_hid_dim, dec_hid_dim):\n        super().__init__()\n        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n\n    def forward(self, hidden, encoder_outputs):\n        batch_size = encoder_outputs.shape[1]\n        src_len = encoder_outputs.shape[0]\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n        attention = self.v(energy).squeeze(2)\n        return torch.softmax(attention, dim=1)\n\n\nclass BahdanauDecoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n        super().__init__()\n        self.output_dim = output_dim\n        self.attention = attention\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=PAD_IDX)\n        self.gru = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, hidden, encoder_outputs):\n        input = input.unsqueeze(0)\n        embedded = self.dropout(self.embedding(input))\n        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        weighted = torch.bmm(a, encoder_outputs).permute(1, 0, 2)\n        rnn_input = torch.cat((embedded, weighted), dim=2)\n        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n        prediction = self.fc_out(torch.cat((output.squeeze(0), weighted.squeeze(0), embedded.squeeze(0)), dim=1))\n        return prediction, hidden.squeeze(0)\n\n\nclass Seq2SeqRNN(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        trg_len, batch_size = trg.shape\n        trg_vocab_size = self.decoder.output_dim\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        encoder_outputs, hidden = self.encoder(src)\n        input = trg[0,:]\n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden, encoder_outputs)\n            outputs[t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[t] if teacher_force else top1\n        return outputs\n\n    def greedy_decode(self, src, max_len=50):\n        with torch.no_grad():\n            encoder_outputs, hidden = self.encoder(src)\n            ys = torch.ones(1, src.shape[1]).fill_(BOS_IDX).long().to(self.device)\n            for _ in range(max_len - 1):\n                input_t = ys[-1, :]\n                output, hidden = self.decoder(input_t, hidden, encoder_outputs)\n                pred_token = output.argmax(1)\n                ys = torch.cat([ys, pred_token.unsqueeze(0)], dim=0)\n                if (pred_token == EOS_IDX).all(): break\n        return ys\n\n\n# -----------------------------------------------------\n# 3.2 Advanced: Transformer\n# -----------------------------------------------------\nclass PositionalEncoding(nn.Module):\n    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(1)   # [maxlen, 1, emb_size]\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: torch.Tensor):\n        # token_embedding shape: [seq_len, batch_size, emb_size]\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size, emb_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n        self.emb_size = emb_size\n\n    def forward(self, tokens):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self, num_enc_layers, num_dec_layers, emb_size, nhead,\n                 src_vocab_size, tgt_vocab_size, dim_feedforward=512, dropout=0.1):\n        super().__init__()\n        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead,\n                                          num_encoder_layers=num_enc_layers,\n                                          num_decoder_layers=num_dec_layers,\n                                          dim_feedforward=dim_feedforward, dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n\n    def forward(self, src, tgt, src_mask, tgt_mask,\n                src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n        src = src.to(device)\n        tgt = tgt.to(device)\n\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n\n    def beam_search_decode(self, src, src_mask, max_len, start_symbol, beam_size=3):\n        src = src.to(device)\n        src_mask = src_mask.to(device)\n\n        memory = self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n\n        sequences = [[list([start_symbol]), 0.0]]\n\n        for _ in range(max_len):\n            all_candidates = []\n            for seq, score in sequences:\n                ys = torch.tensor(seq).unsqueeze(1).to(device)\n                tgt_mask = generate_square_subsequent_mask(ys.size(0)).to(device)\n                out = self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(ys)),\n                                               memory, tgt_mask)\n                out = out.transpose(0, 1)\n                prob = self.generator(out[:, -1])\n                log_probs = torch.log_softmax(prob, dim=1)\n\n                topk_log_probs, topk_words = torch.topk(log_probs, beam_size)\n\n                for i in range(beam_size):\n                    candidate = [seq + [topk_words[0][i].item()],\n                                 score - topk_log_probs[0][i].item()]\n                    all_candidates.append(candidate)\n\n            ordered = sorted(all_candidates, key=lambda tup: tup[1])\n            sequences = ordered[:beam_size]\n\n        return sequences[0][0]\n\n    def greedy_decode(self, src, max_len=50, start_symbol=BOS_IDX):\n        src = src.to(device)\n        src_mask = torch.zeros((src.size(0), src.size(0)), device=device).type(torch.bool)\n\n        # encode source\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        memory = self.transformer.encoder(src_emb, src_key_padding_mask=None)\n\n        # mulai dengan <bos>\n        ys = torch.ones(1, src.size(1), dtype=torch.long, device=device).fill_(start_symbol)\n\n        for _ in range(max_len-1):\n            tgt_emb = self.positional_encoding(self.tgt_tok_emb(ys))\n            tgt_mask = generate_square_subsequent_mask(ys.size(0)).to(device)\n\n            out = self.transformer.decoder(tgt_emb, memory, tgt_mask)\n            out = self.generator(out)\n            next_word = out[-1].argmax(dim=1)\n            ys = torch.cat([ys, next_word.unsqueeze(0)], dim=0)\n\n            if (next_word == EOS_IDX).all():\n                break\n\n        return ys\n\nprint(\"âœ… Model classes defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:01:08.077801Z","iopub.execute_input":"2025-08-23T11:01:08.078000Z","iopub.status.idle":"2025-08-23T11:01:08.106882Z","shell.execute_reply.started":"2025-08-23T11:01:08.077984Z","shell.execute_reply":"2025-08-23T11:01:08.106212Z"}},"outputs":[{"name":"stdout","text":"âœ… Model classes defined.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# =============================================================================\n# STEP 4: TRAINING & EVALUATION UTILITIES\n# =============================================================================\n# This section contains helper functions for training, evaluation, and decoding.\n\ndef create_mask(src, tgt, device):\n    \"\"\"Creates masks for the Transformer model.\"\"\"\n    src_seq_len, tgt_seq_len = src.shape[0], tgt.shape[0]\n    tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len, device)\n    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n\ndef train_epoch(model, loader, optimizer, criterion, clip, is_transformer=False):\n    model.train()\n    epoch_loss = 0\n    for src, trg in tqdm(loader, desc=\"Training\"):\n        src, trg = src.to(device), trg.to(device)\n        optimizer.zero_grad()\n        if is_transformer:\n            trg_input = trg[:-1, :]\n            src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(src, trg_input, device)\n            logits = model(src, trg_input, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask, src_pad_mask)\n            trg_out = trg[1:, :].reshape(-1)\n            logits = logits.reshape(-1, logits.shape[-1])\n        else: # RNN\n            logits = model(src, trg)\n            # FIX: Slice logits to match target shape, avoiding the ValueError\n            trg_out = trg[1:, :].reshape(-1)\n            logits = logits[1:].reshape(-1, logits.shape[-1])\n        loss = criterion(logits, trg_out)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(loader)\n\ndef evaluate_epoch(model, loader, criterion, is_transformer=False):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for src, trg in tqdm(loader, desc=\"Evaluating\"):\n            src, trg = src.to(device), trg.to(device)\n            if is_transformer:\n                trg_input = trg[:-1, :]\n                src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(src, trg_input, device)\n                logits = model(src, trg_input, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask, src_pad_mask)\n                trg_out = trg[1:, :].reshape(-1)\n                logits = logits.reshape(-1, logits.shape[-1])\n            else: # RNN\n                logits = model(src, trg, teacher_forcing_ratio=0.0)\n                # FIX: Slice logits to match target shape\n                trg_out = trg[1:, :].reshape(-1)\n                logits = logits[1:].reshape(-1, logits.shape[-1])\n            loss = criterion(logits, trg_out)\n            epoch_loss += loss.item()\n    return epoch_loss / len(loader)\n\ndef decode_ids(ids, itos):\n    \"\"\"Converts a tensor of IDs back to a string.\"\"\"\n    tokens = []\n    for tok_id in ids:\n        tok = tok_id.item()\n        if tok == EOS_IDX: break\n        if tok not in {BOS_IDX, PAD_IDX}:\n            tokens.append(itos.get(tok, \"<unk>\"))\n    return \" \".join(tokens)\n\ndef calculate_bleu(model, loader, id_itos, device):\n    \"\"\"Calculates SacreBLEU score for the model on a given dataset.\"\"\"\n    model.eval()\n    hypotheses, references = [], []\n    with torch.no_grad():\n        for src, trg in loader:\n            src, trg = src.to(device), trg.to(device)\n            pred_ids = model.greedy_decode(src)\n            for b in range(src.size(1)):\n                hypotheses.append(decode_ids(pred_ids[:, b], id_itos))\n                references.append([decode_ids(trg[:, b], id_itos)])\n    return sacrebleu.corpus_bleu(hypotheses, references).score\n\nprint(\"âœ… Utility functions defined.\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:01:08.108294Z","iopub.execute_input":"2025-08-23T11:01:08.108505Z","iopub.status.idle":"2025-08-23T11:01:08.126561Z","shell.execute_reply.started":"2025-08-23T11:01:08.108478Z","shell.execute_reply":"2025-08-23T11:01:08.125891Z"}},"outputs":[{"name":"stdout","text":"âœ… Utility functions defined.\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# =============================================================================\n# STEP 5: MAIN EXECUTION\n# =============================================================================\n# This is the main block to instantiate and train the models.\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"ðŸš€ Using device: {device}\")\n\n# --- Hyperparameters ---\nN_EPOCHS = 20\nCLIP = 1.0\nLEARNING_RATE = 0.0005\n\n# --- Train and Evaluate RNN Baseline ---\nprint(\"\\n--- Training Baseline RNN + Attention ---\")\nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nENC_HID_DIM = 512\nDEC_HID_DIM = 512\nDROPOUT = 0.5\n\nattn_rnn = BahdanauAttention(ENC_HID_DIM, DEC_HID_DIM)\n# FIX: Corrected DEC_HID_dim to DEC_HID_DIM\nencoder_rnn = BahdanauEncoder(len(en_vocab), ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DROPOUT)\n# FIX: Corrected DEC_HID_dim to DEC_HID_DIM\ndecoder_rnn = BahdanauDecoder(len(id_vocab), DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DROPOUT, attn_rnn)\nmodel_rnn = Seq2SeqRNN(encoder_rnn, decoder_rnn, device).to(device)\n\noptimizer_rnn = optim.Adam(model_rnn.parameters(), lr=LEARNING_RATE)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n\nfor epoch in range(N_EPOCHS):\n    train_loss = train_epoch(model_rnn, train_loader, optimizer_rnn, criterion, CLIP)\n    val_loss = evaluate_epoch(model_rnn, val_loader, criterion)\n    print(f\"Epoch {epoch+1:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}\")\n\n# --- Train and Evaluate Transformer ---\nprint(\"\\n--- Training Transformer ---\")\nEMB_SIZE = 512\nNHEAD = 8\nFFN_HID_DIM = 512\nNUM_ENC_LAYERS = 3\nNUM_DEC_LAYERS = 3\n\nmodel_transformer = Seq2SeqTransformer(NUM_ENC_LAYERS, NUM_DEC_LAYERS, EMB_SIZE, NHEAD,\n                                       len(en_vocab), len(id_vocab), FFN_HID_DIM).to(device)\noptimizer_transformer = optim.Adam(model_transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\nfor epoch in range(N_EPOCHS):\n    train_loss = train_epoch(model_transformer, train_loader, optimizer_transformer, criterion, CLIP, is_transformer=True)\n    val_loss = evaluate_epoch(model_transformer, val_loader, criterion, is_transformer=True)\n    print(f\"Epoch {epoch+1:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}\")\n\n# --- Final Evaluation ---\nprint(\"\\n--- Final Evaluation on Test Set ---\")\nbleu_rnn = calculate_bleu(model_rnn, test_loader, id_itos, device)\nbleu_transformer = calculate_bleu(model_transformer, test_loader, id_itos, device)\nprint(f\"ðŸ† Final BLEU Score (RNN Baseline): {bleu_rnn:.2f}\")\nprint(f\"ðŸ† Final BLEU Score (Transformer): {bleu_transformer:.2f}\")\n\n# --- Show Example Translations ---\ndef show_examples(model, loader, en_itos, id_itos, n=3):\n    print(\"\\n--- Example Translations ---\")\n    model.eval()\n    with torch.no_grad():\n        for i, (src, trg) in enumerate(loader):\n            if i >= n: break\n            src, trg = src.to(device), trg.to(device)\n            pred_ids = model.greedy_decode(src)\n            src_text = decode_ids(src[:, 0], en_itos)\n            trg_text = decode_ids(trg[:, 0], id_itos)\n            pred_text = decode_ids(pred_ids[:, 0], id_itos)\n            print(f\"\\n  SRC:  {src_text}\")\n            print(f\"  TRG:  {trg_text}\")\n            print(f\"  PRED: {pred_text}\")\n\nshow_examples(model_transformer, test_loader, en_itos, id_itos)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:01:08.127379Z","iopub.execute_input":"2025-08-23T11:01:08.127632Z","iopub.status.idle":"2025-08-23T11:07:48.293282Z","shell.execute_reply.started":"2025-08-23T11:01:08.127615Z","shell.execute_reply":"2025-08-23T11:07:48.292429Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Using device: cuda\n\n--- Training Baseline RNN + Attention ---\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.30it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss: 4.984 | Val Loss: 3.991\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.25it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss: 3.672 | Val Loss: 3.278\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.17it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss: 2.890 | Val Loss: 2.919\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.41it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss: 2.331 | Val Loss: 2.676\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.37it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss: 1.893 | Val Loss: 2.616\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.24it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | Train Loss: 1.574 | Val Loss: 2.597\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.24it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | Train Loss: 1.330 | Val Loss: 2.619\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.18it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | Train Loss: 1.162 | Val Loss: 2.616\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.06it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | Train Loss: 1.041 | Val Loss: 2.651\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.16it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.916 | Val Loss: 2.693\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.22it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.821 | Val Loss: 2.684\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.09it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.750 | Val Loss: 2.710\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.19it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.679 | Val Loss: 2.795\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.14it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.622 | Val Loss: 2.823\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 14.98it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.558 | Val Loss: 2.925\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.22it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.518 | Val Loss: 2.939\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.10it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.481 | Val Loss: 2.941\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 14.99it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.441 | Val Loss: 3.039\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.21it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.403 | Val Loss: 3.078\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:12<00:00, 15.23it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.383 | Val Loss: 3.073\n\n--- Training Transformer ---\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.31it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 105.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss: 5.270 | Val Loss: 4.351\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.23it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss: 4.327 | Val Loss: 3.867\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.29it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss: 3.939 | Val Loss: 3.563\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.25it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 111.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss: 3.638 | Val Loss: 3.336\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.27it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss: 3.398 | Val Loss: 3.174\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.30it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | Train Loss: 3.185 | Val Loss: 3.033\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.36it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | Train Loss: 3.000 | Val Loss: 2.911\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.10it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | Train Loss: 2.823 | Val Loss: 2.811\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.22it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | Train Loss: 2.664 | Val Loss: 2.709\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.25it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 2.518 | Val Loss: 2.636\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.39it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 2.378 | Val Loss: 2.558\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.19it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 2.250 | Val Loss: 2.525\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.33it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 2.122 | Val Loss: 2.438\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.23it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 111.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 2.003 | Val Loss: 2.396\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.30it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 1.897 | Val Loss: 2.353\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.44it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 111.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 1.793 | Val Loss: 2.320\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.25it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 113.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 1.685 | Val Loss: 2.283\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.24it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 111.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 1.598 | Val Loss: 2.241\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.27it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 112.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 1.498 | Val Loss: 2.239\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:06<00:00, 29.34it/s]\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 111.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 1.413 | Val Loss: 2.204\n\n--- Final Evaluation on Test Set ---\nðŸ† Final BLEU Score (RNN Baseline): 37.99\nðŸ† Final BLEU Score (Transformer): 16.99\n\n--- Example Translations ---\n\n  SRC:  There's no grass on the moon .\n  TRG:  Tidak ada rumput di bulan .\n  PRED: Tidak ada buku sama sekali tidak ada buku untuk menonton TV sama sekali .\n\n  SRC:  Tom said doing that would be a good idea .\n  TRG:  Tom bilang, hal itu merupakan ide bagus\n  PRED: Tom berkata bahwa dia akan melakukan itu dengan baik .\n\n  SRC:  They went surfing .\n  TRG:  Mereka pergi berselancar .\n  PRED: Mereka pulang lebih tua di dekat dingin .\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# =============================================================================\n# STEP 6: Interactive Translation\n# =============================================================================\n\ndef translate_interactive(sentence, model, src_vocab, trg_itos, device, is_transformer=False):\n    model.eval()\n    \n    # Pre-process the input sentence\n    src_tokens = normalize_and_tokenize(sentence)\n    \n    # Convert tokens to IDs\n    src_ids = torch.tensor(to_ids(src_tokens, src_vocab), dtype=torch.long)\n    src_tensor = src_ids.unsqueeze(1).to(device)\n\n    # Perform greedy decode using the model's built-in method\n    with torch.no_grad():\n        if is_transformer:\n            # For Transformer, we need to pass a different set of arguments for decoding\n            pred_ids = model.greedy_decode(src_tensor)\n        else: # RNN\n            pred_ids = model.greedy_decode(src_tensor)\n    \n    # Decode the output IDs back to text\n    translated_text = decode_ids(pred_ids[:, 0], trg_itos)\n    return translated_text\n\n# --- Interactive Test ---\nprint(\"\\n--- Interactive Test ---\")\n\nkalimat_tes_1 = \"I can do that.\"\nkalimat_tes_2 = \"You must do it.\"\n\n# Menggunakan model Transformer\nterjemahan_transformer_1 = translate_interactive(kalimat_tes_1, model_transformer, en_vocab, id_itos, device, is_transformer=True)\nterjemahan_transformer_2 = translate_interactive(kalimat_tes_2, model_transformer, en_vocab, id_itos, device, is_transformer=True)\n\nprint(f\"\\nModel: Transformer\")\nprint(f\"English: {kalimat_tes_1}\")\nprint(f\"Indonesian: {terjemahan_transformer_1}\")\n\nprint(f\"\\nEnglish: {kalimat_tes_2}\")\nprint(f\"Indonesian: {terjemahan_transformer_2}\")\n\n# Menggunakan model RNN (sebagai perbandingan)\nterjemahan_rnn_1 = translate_interactive(kalimat_tes_1, model_rnn, en_vocab, id_itos, device)\nprint(f\"\\nModel: RNN Baseline\")\nprint(f\"English: {kalimat_tes_1}\")\nprint(f\"Indonesian: {terjemahan_rnn_1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T11:08:31.899549Z","iopub.execute_input":"2025-08-23T11:08:31.899977Z","iopub.status.idle":"2025-08-23T11:08:31.960310Z","shell.execute_reply.started":"2025-08-23T11:08:31.899946Z","shell.execute_reply":"2025-08-23T11:08:31.959330Z"}},"outputs":[{"name":"stdout","text":"\n--- Interactive Test ---\n\nModel: Transformer\nEnglish: I can do that.\nIndonesian: Aku bisa melakukan itu .\n\nEnglish: You must do it.\nIndonesian: Kamu harus melakukannya .\n\nModel: RNN Baseline\nEnglish: I can do that.\nIndonesian: Aku bisa melakukannya .\n","output_type":"stream"}],"execution_count":69}]}